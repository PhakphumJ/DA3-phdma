---
title: "Assignment_1_Wage_PhakphumJ"
author: "Phakphum Jatupitpornchan"
format: html
editor: visual
---

```{r}
#| warning: false
#| echo: false

rm(list=ls())

setwd("D:/Onedrive-CEU/OneDrive - Central European University/CEU/Prediction with Machine Learning/Assignment/DA3-phdma/Assignment 1")

library(readr)
library(dplyr)
library(ggplot2)
library(weights)
library(caret)
library(kableExtra)
library(tidyr)


# Importing the data

DataOriginal <- read_csv("morg-2014-emp.csv")

# Filter - only select 'Miscellaneous agricultural workers, including animal breeders' - 6050

MiscWorkerData = DataOriginal %>%
  filter(occ2012 == 6050)
```


The task is to build a model to predict hourly earnings. I select 'Miscellaneous agricultural workers, including animal breeders' (*occ2012* = 6050) to be my population of interest.\

Firstly, I describe the variables that will be used in constructing the models. Then, the details of each model are presented along with the performance. Finally, I discuss the obtained results.

## Data Dictionary

### Original Variables

This section describes the meaning of each variable that will be used in this modelling exercise.

-   stfips: State codes

-   weight: Weight of observation in sample (How many observations it represents in population)

-   earnwke: Earnings per week

-   uhours: Working hours per week

-   grade92: Highest grade attended; **It is not numerical variable**. (e.g. 31 = Less than 1st grade, 32 = 1st - 4th grade)

```{r}
#| echo: false
MiscWorkerData %>% count(grade92)
```

I will group some education levels above together later.

-   race: Race (1 = White, 2 = Black, 3 = American Indian (AI), 4 = Asian, 5 = Hawaiian/Pacific Islander, 6 = White-Black, 7 = White-AI, 8 = White-Asian)

    ```{r}
    #| echo = FALSE

    ## I run this code to see what races are there in this dataset
    MiscWorkerData %>% count(race)
    ```

I will group some races above together later.

-   age: Age

-   sex: Sex (1 = male, 2 = female)

-   marital: Marital Status (1 = Married civilian spouse present, 2 = Married Armed Foruces spouse present, 3 = Married spouse absent or separated, 4 = Widowed or divorced(Through 88), 5 = Widowed (After 88), 6 = Separated , 7 = Never Married)

    ```{r}
    #| echo: false
    MiscWorkerData %>% count(marital)
    ```

I will group some marital statuses above together later.

-   ownchild: Number of own children **less than** **18** in primary family

-   prcitshp: Citizenship status

    ```{r}
    #| echo: false
    MiscWorkerData %>% count(prcitshp)
    ```

I will group some citizenship statuses above together later.

-   ind02: 3-digit NAICS-based industry code

-   class: Class of worker

    ```{r}
    #| echo: false
    MiscWorkerData %>% count(class)
    ```

I will group some classes above together later.\
 

I discard *chldpres* since it is highly correlated with *ownchild*.

I discard *unionmme* and *unioncov* since 99% of the sample have these two variables = 0.

I discard *lfsr94* since every observations in my sample are employed in the previous week.

*ethnic* is also discarded since it mainly describes the ethnicity of Hispanic workers ,which I think might not be very useful. It also contains 8 categories. If included, we would lose quite some degree of freedom.

### Generated Variables

```{r}
#| echo: false
# Defining the target variable
MiscWorkerData = MiscWorkerData %>% mutate(earnhr = earnwke/uhours)

# grouping race. (1. white 2. black 3. non-white/black)
# Create is_white and is_black variables - use non-white/black as baseline

MiscWorkerData = MiscWorkerData %>% mutate(is_white = case_when(race == 1 ~ 1, race != 1 ~ 0), is_black = case_when(race == 2 ~ 1, race != 2 ~ 0))

# grouping marital statuses. (1. Married with spouse present 2. Married with spouse absent or seperated 3. Widowed or divorced 4. Never Married) - leave the first category out to be baseline

MiscWorkerData = MiscWorkerData %>% mutate(marr_abs = case_when(marital == 3 ~ 1, marital != 3 ~ 0))

MiscWorkerData = MiscWorkerData %>% mutate(wid_div = case_when(marital == 4 | marital == 5 | marital == 6 ~ 1, marital != 4 | marital != 5 | marital != 6 ~ 0))

MiscWorkerData = MiscWorkerData %>% mutate(nevmarr = case_when(marital == 7 ~ 1, marital != 7 ~ 0))

# Recode gender 1 = male, 0 = female. Use female as baseline
MiscWorkerData = MiscWorkerData %>% mutate(male = case_when(sex == 1 ~ 1, sex != 1 ~ 0))

# grouping citizen ship status. (1. Foreign Born, Not a US Citizen 2. Foreign Born, US Cit By Naturalization 3. Native) - use Native as baseline
MiscWorkerData = MiscWorkerData %>% mutate(noncitiz = case_when(prcitshp == 'Foreign Born, Not a US Citizen' ~ 1, prcitshp != 'Foreign Born, Not a US Citizen' ~ 0))

MiscWorkerData = MiscWorkerData %>% mutate(natura = case_when(prcitshp == 'Foreign Born, US Cit By Naturalization' ~ 1, prcitshp != 'Foreign Born, US Cit By Naturalization' ~ 0))

# grouping classes of worker (1. Private, For Profit, 2. Others) use Others as the baseline
MiscWorkerData = MiscWorkerData %>% mutate(forprofit = case_when(class == 'Private, For Profit' ~ 1, class != 'Private, For Profit' ~ 0))

# grouping education levels (1. 6th grade or less 2. 7th - 12th grade but NO Diploma, 3. High school graduate, diploma or GED 4. Some college but no degree 5. Associate degree 6. Bachelor's degree or more) - use 6th grade or less as baseline
MiscWorkerData = MiscWorkerData %>% mutate(than7nodip = case_when(between(grade92, 34, 38) ~ 1, !between(grade92, 34, 38) ~ 0))

MiscWorkerData = MiscWorkerData %>% mutate(HS_GED = case_when(grade92 == 39 ~ 1, grade92 != 39 ~ 0))

MiscWorkerData = MiscWorkerData %>% mutate(Col_ND = case_when(grade92 == 40 ~ 1, grade92 != 40 ~ 0))

MiscWorkerData = MiscWorkerData %>% mutate(asscd = case_when(between(grade92, 41, 42) ~ 1, !between(grade92, 41, 42) ~ 0))

MiscWorkerData = MiscWorkerData %>% mutate(Bach_more = case_when(grade92 >= 43 ~ 1, !grade92 >= 43 ~ 0))
```

```{r}
#| warning: false
#| echo: false


## Added data about minimum wages
minwage = read_csv("Minwage_2014.csv")

# Left join into the main data
MiscWorkerData <- MiscWorkerData %>% left_join(minwage, by = c("stfips" = "State"))
```

The generated variables are:

-   earnhr: Earning per hour **(This is the target variable)**

#### Race

-   is_white: 1 if race is white; 0 otherwise

-   is_black: 1 if race is black; 0 otherwise

#### Marital Status

-   marr_abs: 1 if married with spouse absent or separated; 0 otherwise

-   wid_div: 1 if widowed or divorced; 0 otherwise

-   nevmarr: 1 if never married; 0 otherwise

#### Gender

-   male: 1 if male; 0 otherwise

#### Citizenship Status

-   noncitiz: 1 if not a US citizen; 0 otherwise

-   natura: 1 if Foreign Born, US citizen by Naturalization; 0 otherwise

#### Class

-   forprofit: 1 if working in private in for-profit private organization; 0 otherwise

#### Education Level

-   than7nodip: 1 if 7th - 12th grade but NO Diploma; 0 otherwise

-   HS_GED: 1 if High school graduate, diploma or GED; 0 otherwise

-   Col_ND: 1 if Some college but no degree;; 0 otherwise

-   asscd: 1 if Associate degree; 0 otherwise

-   Bach_more: 1 if Bachelor's degree or more; 0 otherwise

#### Minimum Wage

The sample comes from 50 states. While each state may have different social and economic environment, we would lose significant degree of freedom if we use *stfips*. To compromise, I opt to use data on minimum wages of each state instead. I use published data on the government website and asked ChatGPT to clean it [^1].

[^1]: The data is from :https://www.dol.gov/agencies/whd/state/minimum-wage/history; the recorded process with ChatGPT can be accessed by: https://chat.openai.com/share/dd30493f-c0f8-4b6e-ba9e-ea05e228c719

-   Minwage: the minimum wages in each states in 2014.

## Model Building

I use correlations between the target variable and features to help ordering which variables enter into the models.

```{r}
#| echo: false
## Selecting drop irrelevant variables
WorkingData = MiscWorkerData %>% select(-c(...1, hhid, intmonth, earnwke, race, ethnic, sex, marital, chldpres, prcitshp, state, occ2012, class, unionmme, unioncov, lfsr94, grade92, stfips))
```

```{r}
#| echo: false
#| warning: false

# Calculating correlations matrix. (Only numeric variables)
# weighted correlations
data_mat = as.matrix(WorkingData[,-c(5)])

correlations = wtd.cors(x = data_mat[,-c(1)], y = data_mat[,5], weight = data_mat[,1])

# Put it into table
target_correlations <- data.frame(correlations)
```

```{r}
#| echo: false
# Print the correlations
print(target_correlations)
```

**The specification of each model is:**

**Model 1:** *earnhr* = *f(age, marr_abs, wid_div, nevmarr, noncitiz, natura, than7nodip, HS_GED, Col_ND, asscd, Bach_more)*\
 \
Essentially, age, marital status, citizenship status, and education level are used. These features have the highest correlation with *earnhr*\

**Model 2:** **Model 1** + *(uhours, is_white, is_black, forprofit)*\
    \
which means adding working hours, race, and class of worker to **Model 1** These variables have the next highest values of correlations.\

**Model 3:** **Model 2** + *(male, ownchild)*\
 \
adding gender and number of children to the model.\

**Model 4:** **Model 3** + *(Minwage, ind02)*\
 \
accounting for the variation in minumum wages across state. I added ind02 at the last step because it significantly increases the number of parameters to be estimated\

```{r}
#| echo: false
#| warning: false
## Doing One-Hot Encoding to ind02 to get dummies
# Assuming your data is stored in a variable called 'data' and the nominal variable is 'nominal_variable'
dummy_data <- dummyVars(~ ind02, data = WorkingData)

# Apply the transformation to your data
data_encoded <- predict(dummy_data, newdata = WorkingData)

WorkingData = cbind(WorkingData, data_encoded)

```

```{r}
#| echo: false
#| warning: false
# Doing 5-folds CV
set.seed(2023)
# Getting index for splitting data
folds <- createFolds(WorkingData$earnhr, k = 5, list = TRUE, returnTrain = FALSE)

```

```{r}
#| echo: false
#| warning: false
## Estimating Models and obtains results (5-folds CV)
# Model 1
results <- list()
for (i in 1:5) {
  train_data <- WorkingData[-folds[[i]], ]
  test_data <- WorkingData[folds[[i]], ]
  
  # Train your OLS model
  model_1 <- lm(earnhr ~ age + marr_abs + wid_div + nevmarr + noncitiz + natura + than7nodip + HS_GED + Col_ND + asscd + Bach_more, weights = weight, data = train_data) 
  # Assuming 'target_variable' is the variable you're trying to predict, 
  # and you want to use all other variables as predictors
  
  # Test your model
  predictions <- predict(model_1, newdata = test_data)
  
  # Calculate performance metric MSE
  mse <- mean((test_data$earnhr - predictions)^2)
  
  # Store the results
  results[[i]] <- mse
}
  
  # Get average RMSE
RMSE_CV_Model1 = sqrt(mean(unlist(results)))
  

# Model 2
results <- list()
for (i in 1:5) {
  train_data <- WorkingData[-folds[[i]], ]
  test_data <- WorkingData[folds[[i]], ]
  
  # Train your OLS model
  model_2 <- update(model_1, .~. + uhours, is_white, is_black, forprofit) 
  # Assuming 'target_variable' is the variable you're trying to predict, 
  # and you want to use all other variables as predictors
  
  # Test your model
  predictions <- predict(model_2, newdata = test_data)
  
  # Calculate performance metric MSE
  mse <- mean((test_data$earnhr - predictions)^2)
  
  # Store the results
  results[[i]] <- mse
}
  
  # Get average RMSE
RMSE_CV_Model2 = sqrt(mean(unlist(results)))


# Model 3

results <- list()
for (i in 1:5) {
  train_data <- WorkingData[-folds[[i]], ]
  test_data <- WorkingData[folds[[i]], ]
  
  # Train your OLS model
  model_3 <- update(model_2, .~. + male, ownchild)
  # Assuming 'target_variable' is the variable you're trying to predict, 
  # and you want to use all other variables as predictors
  
  # Test your model
  predictions <- predict(model_3, newdata = test_data)
  
  # Calculate performance metric MSE
  mse <- mean((test_data$earnhr - predictions)^2)
  
  # Store the results
  results[[i]] <- mse
}
  
  # Get average RMSE
RMSE_CV_Model3 = sqrt(mean(unlist(results)))


#Model 4
results <- list()
for (i in 1:5) {
  train_data <- WorkingData[-folds[[i]], ]
  test_data <- WorkingData[folds[[i]], ]
  
  # Train your OLS model
  model_4 <- lm(earnhr ~ . -weight, weights = weight, data = train_data[, -c(5)])
  # Assuming 'target_variable' is the variable you're trying to predict, 
  # and you want to use all other variables as predictors
  
  # Test your model
  predictions <- predict(model_4, newdata = test_data)
  
  # Calculate performance metric MSE
  mse <- mean((test_data$earnhr - predictions)^2)
  
  # Store the results
  results[[i]] <- mse
}
  
  # Get average RMSE
RMSE_CV_Model4 = sqrt(mean(unlist(results)))

```

```{r}
#| echo: false
#| warning: false


## Estimating using the whole sample. Get BIC and RMSE

## Model 1
model_1 <- lm(earnhr ~ age + marr_abs + wid_div + nevmarr + noncitiz + natura + than7nodip + HS_GED + Col_ND + asscd + Bach_more, weights = weight, data = WorkingData) 

# Calculate RMSE in full sample

predictions <- predict(model_1, newdata = WorkingData)
  
# Calculate performance metric RMSE
rmse_full_Model1 <- sqrt(mean((WorkingData$earnhr - predictions)^2))

# Calculate BIC
BIC_full_Model1 <- BIC(model_1)

## Model 2
model_2 <- update(model_1, .~. + uhours, is_white, is_black, forprofit) 

# Calculate RMSE in full sample

predictions <- predict(model_2, newdata = WorkingData)
  
# Calculate performance metric RMSE
rmse_full_Model2 <- sqrt(mean((WorkingData$earnhr - predictions)^2))

# Calculate BIC
BIC_full_Model2 <- BIC(model_2)

## Model 3
model_3 <- update(model_2, .~. + male, ownchild)

# Calculate RMSE in full sample

predictions <- predict(model_3, newdata = WorkingData)
  
# Calculate performance metric RMSE
rmse_full_Model3 <- sqrt(mean((WorkingData$earnhr - predictions)^2))

# Calculate BIC
BIC_full_Model3 <- BIC(model_3)

## Model 4
model_4 <- lm(earnhr ~ . -weight, weights = weight, data = WorkingData[, -c(5)])

# Calculate RMSE in full sample

predictions <- predict(model_4, newdata = WorkingData)
  
# Calculate performance metric RMSE
rmse_full_Model4 <- sqrt(mean((WorkingData$earnhr - predictions)^2))

# Calculate BIC
BIC_full_Model4 <- BIC(model_4)


```

The explanations potential relationships between these predictors and the target variable can be found in the [appendix](#sec-appendix).

Each model is estimated by OLS. The coefficients are estimated by both using cross-validation (5-fold)[^2] and using the whole sample. RMSE and BIC are calculated and shown in next section.

[^2]: The code for performing 5-fold cross-validation is modified from the draft code from ChatGPT. The conversation can be accessed by: https://chat.openai.com/share/9c5a88fd-34b0-42a3-84cd-4e3a889d357d

## Performance

```{r}
#| echo: false
## Compile the performance indicators into a table
ColNames = c('RMSE in full sample', 'RMSE CV', 'BIC in full sample')

# Creating a dataframe
Sum_results <- data.frame(Column1 = c(rmse_full_Model1, rmse_full_Model2, rmse_full_Model3, rmse_full_Model4),
                           Column2 = c(RMSE_CV_Model1, RMSE_CV_Model2, RMSE_CV_Model3, RMSE_CV_Model4),
                           Column3 = c(BIC_full_Model1, BIC_full_Model2, BIC_full_Model3, BIC_full_Model4))


# Adding row names
rownames(Sum_results) <- c("Model 1", "Model 2", "Model 3","Model 4")

# Adding column names
colnames(Sum_results) <- ColNames

```

```{r}
#| echo: false
#| label: tbl-performance
#| tbl-cap: Performance Metrics of Models
kable(Sum_results, align = "c")
```

```{r}
#| echo: false
## plot RMSE

# Convert it to long format
Sum_results = cbind(c("Model 1", "Model 2", "Model 3","Model 4") , Sum_results)
colnames(Sum_results)[1] <- 'Model'

data_long <- gather(Sum_results, key = "Metric", value = "Value", -Model)

```

<center>[RMSE in Full Sample and RMSE CV for Each Model]{style="font-size: larger; font-weight: bold;"}[^3].</center>

[^3]: [The plot is created by using code written by ChatGPT. The conversation can be accessed by: https://chat.openai.com/share/a92f067a-67b3-42c7-94e7-735ab247963f]{style="font-size: larger; font-weight: bold;"}

```{r}
#| echo: false
#| label: fig-RMSE-plot
#| fig-align: center
#| fig-cap: RMSE Plot

# Filter the data to include only "RMSE in full sample" and "RMSE CV"
df_plot <- data_long[data_long$Metric %in% c("RMSE in full sample", "RMSE CV"), ]

# Create a line plot
ggplot(df_plot, aes(x = Model, y = Value, color = Metric, group = Metric)) +
  geom_line() +
  geom_point() +
  labs(x = "Model",
       y = "Value") +
  scale_color_manual(values = c("RMSE in full sample" = "blue", "RMSE CV" = "red")) +   scale_y_continuous(limits = c(6, 7)) +  # Set y-axis limits + 
  theme_minimal() + theme(axis.text = element_text(size = 10))  

```

## Discussion

From @fig-RMSE-plot, it can be seen that both RMSE from using full sample and cross-validation initially decline as the number of variables in the model increases because adding more features increases the goodness-of-fit of the model. However, when 36 coefficients are added to model (from Model 3 to Model 4), the problem of overfitting arises, as reflected by the increasing RMSE from cross-validation. Even though the added features improve the in-sample goodness-of-fit, the overly complex model captures the noise and idiosyncrasies from the training sets which may not be there in test sets (or live data). This exercise highlights the consequence of overfitting the model.

The BIC and RMSE in full sample also reveal interesting information. Going from Model 1 to Model 2, while the goodness-of-fit may improve, the BIC indicates that the gain was small such that it is outweighed by the penalty from increased number of parameters. This imply that the three variables added in Model 2 may only marginally improve the fit. While adding 36 more features to model (from Model 3 to Model 4) may significantly improve the in-sample fit, but it also come at a significant cost, which may be even greater than the gain, as reflected by in the increase in BIC.\

Drawing from the results in @tbl-performance, Model 3 is the best model among the four models in predicting hourly earnings of miscellaneous agricultural workers since it has the lowest value of BIC and RMSE from cross-validation.

## Appendix {#sec-appendix -}

Explanations of potential relationships between the predictors and the target variable

-   Age: When workers become older, they may become physically weaker and have lower productivity. Hence, they may receive lower wages.

-   Marital Status: Marital status may affect productivity and wages through mental health.

-   Citizenship Status: Non-citizen workers may be at disadvantage as the employers may face higher administrative costs when hiring them.

-   Education Level: Education level may increase productivity and availability of outside options of the workers.

-   Working hours: Workers who work longer hours may be viewed positively by employers. They may also work longer hours to compensate for lower wage rates.

-   Race: There may be racial discrimination among some employers.

-   Class of Worker: For-profit private organizations may pay higher wages to their workers since they may be more profitable.

-   Gender: There may be gender discrimination among some employers. Female workers may also need to allocate more time to taking care of their household.

-   Number of Children: Children may affect productivity of their parents through mental health and fatigue effects.

-   Minimum Wages: Workers and employers may use the minimum wages as a reference when negotiating.

-   Industry: Each industry may have different economic environments and prospects.
